{"questionId": "609", "questionFrontendId": "609", "questionTitle": "Find Duplicate File in System", "questionTitleSlug": "find-duplicate-file-in-system", "content": "<p>Given a list <code>paths</code> of directory info, including the directory path, and all the files with contents in this directory, return <em>all the duplicate files in the file system in terms of their paths</em>. You may return the answer in <strong>any order</strong>.</p>\n\n<p>A group of duplicate files consists of at least two files that have the same content.</p>\n\n<p>A single directory info string in the input list has the following format:</p>\n\n<ul>\n\t<li><code>&quot;root/d1/d2/.../dm f1.txt(f1_content) f2.txt(f2_content) ... fn.txt(fn_content)&quot;</code></li>\n</ul>\n\n<p>It means there are <code>n</code> files <code>(f1.txt, f2.txt ... fn.txt)</code> with content <code>(f1_content, f2_content ... fn_content)</code> respectively in the directory &quot;<code>root/d1/d2/.../dm&quot;</code>. Note that <code>n &gt;= 1</code> and <code>m &gt;= 0</code>. If <code>m = 0</code>, it means the directory is just the root directory.</p>\n\n<p>The output is a list of groups of duplicate file paths. For each group, it contains all the file paths of the files that have the same content. A file path is a string that has the following format:</p>\n\n<ul>\n\t<li><code>&quot;directory_path/file_name.txt&quot;</code></li>\n</ul>\n\n<p>&nbsp;</p>\n<p><strong class=\"example\">Example 1:</strong></p>\n<pre><strong>Input:</strong> paths = [\"root/a 1.txt(abcd) 2.txt(efgh)\",\"root/c 3.txt(abcd)\",\"root/c/d 4.txt(efgh)\",\"root 4.txt(efgh)\"]\n<strong>Output:</strong> [[\"root/a/2.txt\",\"root/c/d/4.txt\",\"root/4.txt\"],[\"root/a/1.txt\",\"root/c/3.txt\"]]\n</pre><p><strong class=\"example\">Example 2:</strong></p>\n<pre><strong>Input:</strong> paths = [\"root/a 1.txt(abcd) 2.txt(efgh)\",\"root/c 3.txt(abcd)\",\"root/c/d 4.txt(efgh)\"]\n<strong>Output:</strong> [[\"root/a/2.txt\",\"root/c/d/4.txt\"],[\"root/a/1.txt\",\"root/c/3.txt\"]]\n</pre>\n<p>&nbsp;</p>\n<p><strong>Constraints:</strong></p>\n\n<ul>\n\t<li><code>1 &lt;= paths.length &lt;= 2 * 10<sup>4</sup></code></li>\n\t<li><code>1 &lt;= paths[i].length &lt;= 3000</code></li>\n\t<li><code>1 &lt;= sum(paths[i].length) &lt;= 5 * 10<sup>5</sup></code></li>\n\t<li><code>paths[i]</code> consist of English letters, digits, <code>&#39;/&#39;</code>, <code>&#39;.&#39;</code>, <code>&#39;(&#39;</code>, <code>&#39;)&#39;</code>, and <code>&#39; &#39;</code>.</li>\n\t<li>You may assume no files or directories share the same name in the same directory.</li>\n\t<li>You may assume each given directory info represents a unique directory. A single blank space separates the directory path and file info.</li>\n</ul>\n\n<p>&nbsp;</p>\n<p><strong>Follow up:</strong></p>\n\n<ul>\n\t<li>Imagine you are given a real file system, how will you search files? DFS or BFS?</li>\n\t<li>If the file content is very large (GB level), how will you modify your solution?</li>\n\t<li>If you can only read the file by 1kb each time, how will you modify your solution?</li>\n\t<li>What is the time complexity of your modified solution? What is the most time-consuming part and memory-consuming part of it? How to optimize?</li>\n\t<li>How to make sure the duplicated files you find are not false positive?</li>\n</ul>\n", "difficulty": "Medium", "stats": "{\"totalAccepted\": \"140.5K\", \"totalSubmission\": \"207.2K\", \"totalAcceptedRaw\": 140503, \"totalSubmissionRaw\": 207152, \"acRate\": \"67.8%\"}", "similarQuestions": "[{\"title\": \"Delete Duplicate Folders in System\", \"titleSlug\": \"delete-duplicate-folders-in-system\", \"difficulty\": \"Hard\", \"translatedTitle\": null}]", "categoryTitle": "Algorithms", "topicTags": [{"name": "Array", "slug": "array"}, {"name": "Hash Table", "slug": "hash-table"}, {"name": "String", "slug": "string"}], "normalized_title": "find_duplicate_file_in_system"}